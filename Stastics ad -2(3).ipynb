{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1da262fb-9031-4b80-b301-55eeffe0faaf",
   "metadata": {},
   "source": [
    "Q1. Explain the assumptions required to use ANOVA and provide examples of violations that could impact\n",
    "the validity of the results."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ced9eaa9-38bb-4c7a-977a-dda9a6fd432e",
   "metadata": {},
   "source": [
    "ANOVA (Analysis of Variance) is a statistical method used to compare the means of three or more groups or treatments to determine if there are any significant differences among them.\n",
    "\n",
    "To use ANOVA and ensure the validity of its results, certain assumptions need to be met. These assumptions are :\n",
    "\n",
    "Independence : The observations within each group or treatment are independent of each other. This means that the values in one group should not be influenced or related to the values in another group.\n",
    "\n",
    "Normality : The data in each group should follow a normal distribution. The normality assumption is particularly important when the sample sizes are small, as ANOVA tends to be robust to violations when the sample sizes are large.\n",
    "\n",
    "Homogeneity of Variance (Homoscedasticity) : The variability of the data (variance) within each group should be roughly equal. In other words, the spread of the data points around the group means should be similar across all groups.\n",
    "\n",
    "Absence of outliers : There must no outliers in the data points\n",
    "\n",
    "Examples of Violations:\n",
    "\n",
    "Violation of Independence: In some experimental designs, the independence assumption may be violated if there is a hierarchical or nested structure in the data. For example, if you measure the performance of students within different classrooms, the students within the same classroom may not be independent of each other due to shared characteristics or teaching styles.\n",
    "\n",
    "Violation of Normality: If the data in any of the groups deviates significantly from a normal distribution, it can impact the validity of ANOVA results. For instance, if the data is strongly skewed or has heavy tails, the normality assumption may not hold.\n",
    "\n",
    "Violation of Homoscedasticity: Unequal variances among groups can lead to biased ANOVA results. For example, if the variability of test scores in one group is much larger than that in another group, the assumption of homogeneity of variance may not be met."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c984d5-8d8b-464b-99b8-220f1433739e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e6c1329a-ef47-47a4-91ec-85e9a127f4c2",
   "metadata": {},
   "source": [
    "Q2. What are the three types of ANOVA, and in what situations would each be used?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3cafebff-f4f8-41d5-9417-fcf9c20670b5",
   "metadata": {},
   "source": [
    "The three types of ANOVA (Analysis of Variance) are:\n",
    "\n",
    "One-Way ANOVA:\n",
    "\n",
    "\n",
    "One-Way ANOVA is used when there is one categorical independent variable (also known as a factor) with three or more levels or groups, and we want to compare the means of a continuous dependent variable across these groups.\n",
    "It is suitable for situations where we have one factor and want to determine if there are any significant differences in the means of the dependent variable across the different levels of that factor.\n",
    "Example: Suppose we want to compare the average test scores of students in three different teaching methods (A, B, and C) to see if there is a significant difference in performance.\n",
    "\n",
    "Two-Way ANOVA:\n",
    "\n",
    "\n",
    "Two-Way ANOVA is used when there are two categorical independent variables (factors), and we want to examine the interaction between these two factors and their effects on a continuous dependent variable.\n",
    "It is suitable for situations where we have two factors, and we want to investigate how the means of the dependent variable vary across the combinations of levels of both factors.\n",
    "Example: Suppose we want to analyze the effect of two factors, gender (male and female) and teaching method (A, B, and C), on the performance of students in a test.\n",
    "\n",
    "Three-Way ANOVA:\n",
    "\n",
    "\n",
    "Three-Way ANOVA is an extension of the two-way ANOVA and is used when there are three categorical independent variables (factors).\n",
    "It is suitable for situations where we have three factors, and we want to examine their individual effects and their interactions on a continuous dependent variable.\n",
    "Example: Suppose we want to study the effects of three factors: age group (young, middle-aged, and old), treatment type (A, B, and C), and location (urban and rural) on the response time of participants in a cognitive test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1142c27d-a8c7-4f93-ba62-b5f8ba049286",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "727ae9fd-4f47-4465-a04a-205271d9daa4",
   "metadata": {},
   "source": [
    "Q3. What is the partitioning of variance in ANOVA, and why is it important to understand this concept?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1918341b-4d84-4918-b369-dec4c0a60ebe",
   "metadata": {},
   "source": [
    "Partitioning of Variance in ANOVA-\n",
    "ANOVA is fundamentally about partitioning the total variability in a dataset into different components.The total variation represents the overall spread of data points around the grand mean.   \n",
    "\n",
    "The core idea is to decompose this total variation into two primary components:\n",
    "\n",
    "1)Between-group variance: This measures the variability between the means of different groups. It reflects how much the group means differ from the overall mean.   \n",
    "\n",
    "2)Within-group variance: This measures the variability of individual data points within each group. It represents the random variation around the group means.\n",
    "\n",
    "By comparing these two components, ANOVA determines if the differences between group means are statistically significant. A large between-group variance relative to the within-group variance suggests that the group means are likely different, not just due to random chance.   \n",
    "\n",
    "Understanding this partitioning is crucial because it forms the basis for the F-test statistic in ANOVA. The F-test compares the ratio of between-group variance to within-group variance. A larger F-value indicates a higher likelihood that the group differences are real and not just noise.   \n",
    "\n",
    "In essence, partitioning variance allows us to quantify and compare the differences between groups, helping us make informed conclusions about the data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2177b76d-7df4-476a-ba2e-e12b8bc34d69",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "05500345-ec8a-408b-b559-271ff38f78a6",
   "metadata": {},
   "source": [
    "Q4. How would you calculate the total sum of squares (SST), explained sum of squares (SSE), and residual\n",
    "sum of squares (SSR) in a one-way ANOVA using Python?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df36815a-5d24-40f6-8805-a903cc99f5ef",
   "metadata": {},
   "source": [
    "Calculate the Total Sum of Squares (SST):\n",
    "SST represents the total variability in the dependent variable.\n",
    "\n",
    "The sum of squared differences between individual data points (yi) and the mean of the response variable (y).\n",
    "\n",
    "SST = Σ(yi – y)2\n",
    "\n",
    "Calculate the Explained Sum of Squares (SSE):\n",
    "SSE represents the variability in the dependent variable that can be attributed to the differences between the group means (treatments).\n",
    "The sum of squared differences between predicted data points (ŷi) and observed data points (yi).\n",
    "\n",
    "SSE = Σ(ŷi – yi)2\n",
    "\n",
    "Calculate the Residual Sum of Squares (SSR):\n",
    "SSR represents the unexplained variability in the dependent variable within each group.\n",
    "The sum of squared differences between predicted data points (ŷi) and the mean of the response variable(y).\n",
    "\n",
    "SSR = Σ(ŷi – y)2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0bac4635-93d8-4978-8706-4604943cb940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hours</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>74</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>80</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>76</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   hours  score\n",
       "0      1     68\n",
       "1      1     76\n",
       "2      1     74\n",
       "3      2     80\n",
       "4      2     76"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Creating the Data\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "#create pandas DataFrame\n",
    "df = pd.DataFrame({'hours': [1, 1, 1, 2, 2, 2, 2, 2, 3, 3,\n",
    "                             3, 4, 4, 4, 5, 5, 6, 7, 7, 8],\n",
    "                   'score': [68, 76, 74, 80, 76, 78, 81, 84, 86, 83,\n",
    "                             88, 85, 89, 94, 93, 94, 96, 89, 92, 97]})\n",
    "\n",
    "#view first five rows of DataFrame\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d94c74de-52fd-46d0-8712-c814cbde9409",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SSE :  331.07488479262696\n",
      "SSR :  917.4751152073725\n",
      "SST :  1248.5499999999995\n"
     ]
    }
   ],
   "source": [
    "#Fit a regression model\n",
    "import statsmodels.api as sm\n",
    "\n",
    "#define response variable\n",
    "y = df['score']\n",
    "\n",
    "#define predictor variable\n",
    "x = df[['hours']]\n",
    "\n",
    "#add constant to predictor variables\n",
    "x = sm.add_constant(x)\n",
    "\n",
    "#fit linear regression model\n",
    "model = sm.OLS(y, x).fit()\n",
    "\n",
    "#Calculate SSE,SSR,SST\n",
    "import numpy as np\n",
    "\n",
    "#calculate sse\n",
    "sse = np.sum((model.fittedvalues - df.score)**2)\n",
    "print(\"SSE : \", sse)\n",
    "\n",
    "\n",
    "#calculate ssr\n",
    "ssr = np.sum((model.fittedvalues - df.score.mean())**2)\n",
    "print(\"SSR : \", ssr)\n",
    "\n",
    "\n",
    "#calculate sst\n",
    "sst = ssr + sse\n",
    "print(\"SST : \", sst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87ef8b52-d4e3-4979-8f61-d752192c8cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0414041e-966f-482b-8543-9f2340ce1930",
   "metadata": {},
   "source": [
    "Q5. In a two-way ANOVA, how would you calculate the main effects and interaction effects using Python?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8156cc84-495d-4d05-9075-13f09060dc52",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                             df     sum_sq   mean_sq         F    PR(>F)\n",
      "C(Fertilizer)               1.0   0.033333  0.033333  0.012069  0.913305\n",
      "C(Watering)                 1.0   0.000369  0.000369  0.000133  0.990865\n",
      "C(Fertilizer):C(Watering)   1.0   0.040866  0.040866  0.014796  0.904053\n",
      "Residual                   28.0  77.333333  2.761905       NaN       NaN\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>         <td>height</td>      <th>  R-squared:         </th> <td>   0.000</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>  -0.035</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td> 0.01207</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sun, 28 Jul 2024</td> <th>  Prob (F-statistic):</th>  <td> 0.913</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>04:57:37</td>     <th>  Log-Likelihood:    </th> <td> -56.772</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>    30</td>      <th>  AIC:               </th> <td>   117.5</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>    28</td>      <th>  BIC:               </th> <td>   120.3</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     1</td>      <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "                        <td></td>                           <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Intercept</th>                                     <td>   14.8000</td> <td>    0.429</td> <td>   34.491</td> <td> 0.000</td> <td>   13.921</td> <td>   15.679</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Fertilizer)[T.weekly]</th>                       <td>   -0.0222</td> <td>    0.202</td> <td>   -0.110</td> <td> 0.913</td> <td>   -0.437</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Watering)[T.weekly]</th>                         <td>   -0.0222</td> <td>    0.202</td> <td>   -0.110</td> <td> 0.913</td> <td>   -0.437</td> <td>    0.392</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>C(Fertilizer)[T.weekly]:C(Watering)[T.weekly]</th> <td>   -0.0222</td> <td>    0.202</td> <td>   -0.110</td> <td> 0.913</td> <td>   -0.437</td> <td>    0.392</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td> 0.177</td> <th>  Durbin-Watson:     </th> <td>   0.916</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.915</td> <th>  Jarque-Bera (JB):  </th> <td>   0.011</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 0.029</td> <th>  Prob(JB):          </th> <td>   0.995</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 2.929</td> <th>  Cond. No.          </th> <td>2.61e+32</td>\n",
       "</tr>\n",
       "</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.<br/>[2] The smallest eigenvalue is 9.5e-64. This might indicate that there are<br/>strong multicollinearity problems or that the design matrix is singular."
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                 height   R-squared:                       0.000\n",
       "Model:                            OLS   Adj. R-squared:                 -0.035\n",
       "Method:                 Least Squares   F-statistic:                   0.01207\n",
       "Date:                Sun, 28 Jul 2024   Prob (F-statistic):              0.913\n",
       "Time:                        04:57:37   Log-Likelihood:                -56.772\n",
       "No. Observations:                  30   AIC:                             117.5\n",
       "Df Residuals:                      28   BIC:                             120.3\n",
       "Df Model:                           1                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "=================================================================================================================\n",
       "                                                    coef    std err          t      P>|t|      [0.025      0.975]\n",
       "-----------------------------------------------------------------------------------------------------------------\n",
       "Intercept                                        14.8000      0.429     34.491      0.000      13.921      15.679\n",
       "C(Fertilizer)[T.weekly]                          -0.0222      0.202     -0.110      0.913      -0.437       0.392\n",
       "C(Watering)[T.weekly]                            -0.0222      0.202     -0.110      0.913      -0.437       0.392\n",
       "C(Fertilizer)[T.weekly]:C(Watering)[T.weekly]    -0.0222      0.202     -0.110      0.913      -0.437       0.392\n",
       "==============================================================================\n",
       "Omnibus:                        0.177   Durbin-Watson:                   0.916\n",
       "Prob(Omnibus):                  0.915   Jarque-Bera (JB):                0.011\n",
       "Skew:                           0.029   Prob(JB):                        0.995\n",
       "Kurtosis:                       2.929   Cond. No.                     2.61e+32\n",
       "==============================================================================\n",
       "\n",
       "Notes:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "[2] The smallest eigenvalue is 9.5e-64. This might indicate that there are\n",
       "strong multicollinearity problems or that the design matrix is singular.\n",
       "\"\"\""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Importing libraries\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "  \n",
    "# Create a dataframe\n",
    "dataframe = pd.DataFrame({'Fertilizer': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'Watering': np.repeat(['daily', 'weekly'], 15),\n",
    "                          'height': [14, 16, 15, 15, 16, 13, 12, 11,\n",
    "                                     14, 15, 16, 16, 17, 18, 14, 13, \n",
    "                                     14, 14, 14, 15, 16, 16, 17, 18,\n",
    "                                     14, 13, 14, 14, 14, 15]})\n",
    "  \n",
    "  \n",
    "# Performing two-way ANOVA\n",
    "model = ols('height ~ C(Fertilizer) + C(Watering) + C(Fertilizer):C(Watering)',data=dataframe).fit()\n",
    "result = sm.stats.anova_lm(model, type=2)\n",
    "  \n",
    "# Print the result\n",
    "print(result)\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bb3bf4-9a09-4546-bcff-c47e75eb3ec6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8f426ad0-f35f-4a5b-b664-63cfd30fea29",
   "metadata": {},
   "source": [
    "Q6. Suppose you conducted a one-way ANOVA and obtained an F-statistic of 5.23 and a p-value of 0.02.\n",
    "What can you conclude about the differences between the groups, and how would you interpret these\n",
    "results?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20fd9434-de55-430b-ae8a-3984f4003637",
   "metadata": {},
   "source": [
    "In a one-way ANOVA, the F-statistic is used to test whether there are significant differences between the means of three or more groups. The associated p-value indicates the probability of observing the data, or more extreme data, under the assumption that the group means are all equal (null hypothesis).\n",
    "\n",
    "The F-statistic:\n",
    "\n",
    "The F-statistic measures the ratio of variability between groups to variability within groups. A larger F-statistic suggests that the variability between group means is significantly greater than the variability within groups.\n",
    "\n",
    "The p-value:\n",
    "\n",
    "The p-value indicates the probability of obtaining the observed data or more extreme data under the assumption that there are no true differences between the group means (null hypothesis). A smaller p-value suggests that the observed differences are unlikely to have occurred by chance alone. Interpretation:\n",
    "\n",
    "Since the p-value (0.02) is less than the chosen significance level (α) of 0.05 (commonly used so assumption is made), we reject the null hypothesis.\n",
    "This means that there is sufficient evidence to conclude that there are statistically significant differences between the means of the groups being compared."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36cdea4d-e5cf-4fdd-8d54-207ccd29446b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a3464d6c-eaf8-4bf1-bb72-7ea159b3235b",
   "metadata": {},
   "source": [
    "Q7. In a repeated measures ANOVA, how would you handle missing data, and what are the potential\n",
    "consequences of using different methods to handle missing data?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32623f2b-56f0-46da-af3b-dd3d64949a81",
   "metadata": {},
   "source": [
    "In a repeated measures ANOVA, missing data can occur when participants have incomplete responses or when data is lost during data collection or processing. Handling missing data appropriately is crucial because it can impact the validity and reliability of the results.\n",
    "\n",
    "There are several methods to handle missing data in a repeated measures ANOVA:\n",
    "\n",
    "1)Complete Case Analysis (Listwise Deletion): This method involves excluding any case with missing data in any of the variables being analyzed. While it is the simplest approach, it can lead to biased results if the data is not missing completely at random. It can also reduce the sample size and statistical power, potentially leading to less reliable results.\n",
    "\n",
    "2)Mean Imputation: In this method, missing data in a variable are replaced by the mean of that variable from the observed cases. While this is a straightforward approach, it may distort the distribution of the variable and underestimate the standard error, leading to overly optimistic statistical significance.\n",
    "\n",
    "3)Last Observation Carried Forward (LOCF): LOCF imputes missing data with the value of the last observed data point. This method assumes that the data follows a linear pattern, which may not be appropriate for all situations.\n",
    "\n",
    "4)Multiple Imputation: Multiple imputation involves creating multiple plausible imputations for the missing data, incorporating uncertainty in the imputation process. This approach can provide more reliable estimates and standard errors. However, it can be computationally intensive and may require making assumptions about the missing data mechanism.\n",
    "\n",
    "5)Maximum Likelihood Estimation (MLE): MLE is a statistical approach that estimates parameters by maximizing the likelihood function. In the context of missing data, it allows for the use of all available data and provides unbiased estimates under the assumption that data is missing at random.\n",
    "\n",
    "6)Pattern-Mixture Models: These models involve considering different patterns of missingness and fitting separate models for each pattern. This approach can be complex but may provide more accurate estimates when the missing data mechanism is related to the outcome."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45c5c9c9-9f4f-472a-96f4-0e13002da429",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "e82ca2f1-f258-4628-9ac9-8723660766b0",
   "metadata": {},
   "source": [
    "Q8. What are some common post-hoc tests used after ANOVA, and when would you use each one? Provide\n",
    "an example of a situation where a post-hoc test might be necessary."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f7af74e-a7e5-45cc-bb84-9c9eec42680a",
   "metadata": {},
   "source": [
    "Post-hoc tests are used in ANOVA to compare specific pairs of groups after a significant main effect or interaction effect has been found.\n",
    "\n",
    "Some common post-hoc tests include are :\n",
    "\n",
    "1)Tukey's Honestly Significant Difference (HSD): Tukey's HSD test is widely used when comparing all possible pairs of group means. It controls the familywise error rate, ensuring that the overall experimentwise error rate remains at a desired level (typically 0.05). This test is appropriate when you have equal group sizes and homogeneity of variances.\n",
    "\n",
    "2)Bonferroni Correction: The Bonferroni correction is a simple method to adjust the significance level for multiple comparisons. It divides the desired alpha level (usually 0.05) by the number of comparisons being made. This method is more conservative but can be applied to any set of comparisons.\n",
    "\n",
    "3)Sidak Correction: Similar to Bonferroni, the Sidak correction is another way to adjust the significance level for multiple comparisons. It is considered slightly more powerful than Bonferroni.\n",
    "\n",
    "4)Dunnett's Test: Dunnett's test is used when you have one control group and you want to compare it to multiple treatment groups. It controls the Type I error rate by considering the control group as a reference.\n",
    "\n",
    "5)Scheffé Test: The Scheffé test is more conservative than Tukey's HSD and is suitable when group sizes are unequal and variances are not homogeneous. It can be used for all possible pairwise comparisons.\n",
    "\n",
    "6)Fisher's Least Significant Difference (LSD): Fisher's LSD test is less conservative than Tukey's HSD, but it is not appropriate when there are unequal group sizes or non-homogeneous variances.\n",
    "\n",
    "The choice of post-hoc test depends on the research question, the number of groups, and the prior knowledge about which groups are likely to differ. A post-hoc test might be necessary when an ANOVA indicates a significant difference between groups but does not identify which specific groups differ.\n",
    "\n",
    "For example, a researcher might conduct an ANOVA to examine the effect of different instructional methods on student achievement. If the ANOVA shows a significant main effect of instructional method, the researcher might use a post-hoc test to compare the mean scores of each instructional method to identify which methods are significantly different from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6189e1f8-0333-4ef4-9c47-3fb7b0ac1c70",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "758d410a-d963-47af-8592-342fd3352c0a",
   "metadata": {},
   "source": [
    "Q9. A researcher wants to compare the mean weight loss of three diets: A, B, and C. They collect data from\n",
    "50 participants who were randomly assigned to one of the diets. Conduct a one-way ANOVA using Python\n",
    "to determine if there are any significant differences between the mean weight loss of the three diets.\n",
    "Report the F-statistic and p-value, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "23a63838-9b10-41a3-9d3d-2a02652b79db",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F-statistic: 41.80444706032352\n",
      "p-value: 4.2309140010930765e-15\n",
      "We reject the null hypothesis.\n",
      "Final Conclusion : The mean weight loss is different for at least one diet.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate simulated data assuming normal distribution with same variance\n",
    "np.random.seed(20)\n",
    "diet_A = np.random.normal(5, 1, 50)\n",
    "diet_B = np.random.normal(4, 1, 50)\n",
    "diet_C = np.random.normal(3, 1, 50)\n",
    "\n",
    "# Perform one-way ANOVA\n",
    "f_statistic, p_value = stats.f_oneway(diet_A, diet_B, diet_C)\n",
    "\n",
    "# Set significance level\n",
    "alpha = 0.05\n",
    "\n",
    "# Null hypothesis: The mean weight loss is the same for all three diets.\n",
    "# Alternative hypothesis: The mean weight loss is different for at least one diet.\n",
    "null_hypothesis = \"The mean weight loss is the same for all three diets.\"\n",
    "alternate_hypothesis = \"The mean weight loss is different for at least one diet.\"\n",
    "\n",
    "print(\"F-statistic:\", f_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "if p_value < alpha:\n",
    "    print(\"We reject the null hypothesis.\")\n",
    "    print(f\"Final Conclusion : {alternate_hypothesis}\")\n",
    "else:\n",
    "    print(\"We fail to reject the null hypothesis.\")\n",
    "    print(f\"Final Conclusion : {null_hypothesis}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aa5ce95-7ff4-4648-af5c-fe79244a49df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c7de6ed9-a4cb-4018-9b81-ef4bf57b687f",
   "metadata": {},
   "source": [
    "Q10. A company wants to know if there are any significant differences in the average time it takes to\n",
    "complete a task using three different software programs: Program A, Program B, and Program C. They\n",
    "randomly assign 30 employees to one of the programs and record the time it takes each employee to\n",
    "complete the task. Conduct a two-way ANOVA using Python to determine if there are any main effects or\n",
    "interaction effects between the software programs and employee experience level (novice vs.\n",
    "experienced). Report the F-statistics and p-values, and interpret the results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e09beea3-903c-4f96-b5f9-733d449c09b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                  df       sum_sq    mean_sq         F  \\\n",
      "C(Software)                      2.0     9.309580   4.654790  0.216246   \n",
      "C(ExperienceLevel)               1.0    31.851905  31.851905  1.479736   \n",
      "C(Software):C(ExperienceLevel)   2.0    52.479686  26.239843  1.219018   \n",
      "Residual                        84.0  1808.132913  21.525392       NaN   \n",
      "\n",
      "                                  PR(>F)  \n",
      "C(Software)                     0.805984  \n",
      "C(ExperienceLevel)              0.227223  \n",
      "C(Software):C(ExperienceLevel)  0.300694  \n",
      "Residual                             NaN  \n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.formula.api import ols\n",
    "\n",
    "# Generate random data for the example (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "\n",
    "# Software programs: A, B, C\n",
    "software_programs = np.random.choice(['A', 'B', 'C'], size=90)\n",
    "\n",
    "# Employee experience level: Novice, Experienced\n",
    "experience_level = np.random.choice(['Novice', 'Experienced'], size=90)\n",
    "\n",
    "# Random time data for each combination of program and experience level\n",
    "time_to_complete_task = np.random.normal(loc=20, scale=5, size=90)\n",
    "\n",
    "# Create a DataFrame\n",
    "data = pd.DataFrame({'Software': software_programs,\n",
    "                     'ExperienceLevel': experience_level,\n",
    "                     'Time': time_to_complete_task})\n",
    "\n",
    "# Perform the two-way ANOVA\n",
    "model = ols('Time ~ C(Software) + C(ExperienceLevel) + C(Software):C(ExperienceLevel)', data=data).fit()\n",
    "anova_table = sm.stats.anova_lm(model)\n",
    "\n",
    "# Report the results\n",
    "print(anova_table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d2d9094-1e8b-4d0b-ab4b-d323eb108011",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f22f6697-d5c4-41b5-9f75-7235f93782df",
   "metadata": {},
   "source": [
    "Q11. An educational researcher is interested in whether a new teaching method improves student test\n",
    "scores. They randomly assign 100 students to either the control group (traditional teaching method) or the\n",
    "experimental group (new teaching method) and administer a test at the end of the semester. Conduct a\n",
    "two-sample t-test using Python to determine if there are any significant differences in test scores\n",
    "between the two groups. If the results are significant, follow up with a post-hoc test to determine which\n",
    "group(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "377b3fc4-429e-4707-bf61-ce1bef3fb0ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Two-sample t-test:\n",
      "t-statistic: -7.738786904885968\n",
      "p-value: 5.026085102727666e-13\n",
      "There is a significant difference in test scores between the control and experimental groups.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate random data for the example (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "\n",
    "control_group = np.random.normal(loc=75, scale=5, size=100)\n",
    "experimental_group = np.random.normal(loc=80, scale=6, size=100)\n",
    "\n",
    "# Perform two-sample t-test\n",
    "t_statistic, p_value = stats.ttest_ind(control_group, experimental_group)\n",
    "\n",
    "# Report the results\n",
    "print(\"Two-sample t-test:\")\n",
    "print(\"t-statistic:\", t_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in test scores between the control and experimental groups.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in test scores between the control and experimental groups.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "af48c32c-08b6-4049-a4da-a02f2ae9b06d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tukey's HSD post-hoc test:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05   \n",
      "========================================================\n",
      " group1    group2    meandiff p-adj lower  upper  reject\n",
      "--------------------------------------------------------\n",
      "Control Experimental   5.6531   0.0 4.2125 7.0936   True\n",
      "--------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Combine the test scores and group information into a DataFrame\n",
    "data = pd.DataFrame({'Test_Score': np.concatenate([control_group, experimental_group]),\n",
    "                     'Group': ['Control'] * 100 + ['Experimental'] * 100})\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(data['Test_Score'], data['Group'])\n",
    "\n",
    "# Report the results\n",
    "print(\"\\nTukey's HSD post-hoc test:\")\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77f1c93-9d51-458a-a379-7b7c7dc0c6e6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "8d88cca3-c6e4-4071-bb98-b7c5e96348af",
   "metadata": {},
   "source": [
    "Q12. A researcher wants to know if there are any significant differences in the average daily sales of three\n",
    "retail stores: Store A, Store B, and Store C. They randomly select 30 days and record the sales for each store\n",
    "on those days. Conduct a repeated measures ANOVA using Python to determine if there are any\n",
    "\n",
    "significant differences in sales between the three stores. If the results are significant, follow up with a post-\n",
    "hoc test to determine which store(s) differ significantly from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d40d84fe-c643-4810-b9ca-5143882582e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One-way repeated measures ANOVA:\n",
      "F-statistic: 23.62763182315457\n",
      "p-value: 6.369054894762179e-09\n",
      "There is a significant difference in average daily sales between the three stores.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.stats as stats\n",
    "\n",
    "# Generate random data for the example (replace this with your actual data)\n",
    "np.random.seed(42)\n",
    "\n",
    "store_A_sales = np.random.normal(loc=1000, scale=100, size=30)\n",
    "store_B_sales = np.random.normal(loc=950, scale=90, size=30)\n",
    "store_C_sales = np.random.normal(loc=1100, scale=110, size=30)\n",
    "\n",
    "# Combine the sales data and group information into a DataFrame\n",
    "data = pd.DataFrame({'Sales': np.concatenate([store_A_sales, store_B_sales, store_C_sales]),\n",
    "                     'Store': ['A'] * 30 + ['B'] * 30 + ['C'] * 30})\n",
    "\n",
    "# Perform one-way repeated measures ANOVA\n",
    "F_statistic, p_value = stats.f_oneway(store_A_sales, store_B_sales, store_C_sales)\n",
    "\n",
    "# Report the results\n",
    "print(\"One-way repeated measures ANOVA:\")\n",
    "print(\"F-statistic:\", F_statistic)\n",
    "print(\"p-value:\", p_value)\n",
    "\n",
    "# Interpret the results\n",
    "alpha = 0.05  # Significance level\n",
    "\n",
    "if p_value < alpha:\n",
    "    print(\"There is a significant difference in average daily sales between the three stores.\")\n",
    "else:\n",
    "    print(\"There is no significant difference in average daily sales between the three stores.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "19d0269c-ae09-4e76-9c3a-99ac177adc53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Tukey's HSD post-hoc test:\n",
      "  Multiple Comparison of Means - Tukey HSD, FWER=0.05  \n",
      "=======================================================\n",
      "group1 group2 meandiff p-adj    lower    upper   reject\n",
      "-------------------------------------------------------\n",
      "     A      B -42.0899 0.2045 -100.5291  16.3492  False\n",
      "     A      C  120.232    0.0   61.7929 178.6712   True\n",
      "     B      C 162.3219    0.0  103.8828 220.7611   True\n",
      "-------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "from statsmodels.stats.multicomp import pairwise_tukeyhsd\n",
    "\n",
    "# Perform Tukey's HSD post-hoc test\n",
    "tukey_results = pairwise_tukeyhsd(data['Sales'], data['Store'])\n",
    "\n",
    "# Report the results\n",
    "print(\"\\nTukey's HSD post-hoc test:\")\n",
    "print(tukey_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0136b90a-01f6-4597-8acb-4e12144143e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
